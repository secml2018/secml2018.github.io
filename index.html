<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="NIPS 2018 Workshop on Security in Machine Learning">

  <title>NIPS 2018 Workshop on Security in Machine Learning</title>

  <!-- Bootstrap core CSS -->
  <link href="bootstrap.min.css" rel="stylesheet">
</head>

<body>

<!-- Begin page content -->
<main role="main" class="container">
  <h1 class="mt-5">NIPS 2018 Workshop on Security in Machine Learning</h1>
  <p class="mb-0"><b>Date:</b> December 7, 2018 (Friday)</p>
  <p class="mb-0"><b>Location:</b> Montreal, Canada (co-located with <a href="https://nips.cc/" target="_blank">NIPS 2018</a>)</p>
  <p class="mb-0"><b>Submission deadline:</b> October 26, 2018 Anywhere on Earth (AoE)</p>
  <p class="mb-0"><b>Notification sent to authors:</b> November 12, 2018 Anywhere on Earth (AoE)</p>
  <p class="mb-0"><b>Submission server:</b> <a href="https://cmt3.research.microsoft.com/SECML2018" target="_blank">https://cmt3.research.microsoft.com/SECML2018</a> (the server is now open)</p>
  <p class="mb-0"><b>Contact:</b> secml2018-org@googlegroups.com (this will email all organizers)</p>
  <p><b>Room:</b> TBD</p>
  <p>
    <i>Abstract</i>—There is growing recognition that ML exposes new vulnerabilities in software systems. Some of the threat vectors explored so far include training data poisoning, adversarial examples or model extraction. Yet, the technical community's understanding of the nature and extent of the resulting vulnerabilities remains limited. This is due in part to (1) the large attack surface exposed by ML algorithms because they were designed for deployment in benign environments---as exemplified by the IID assumption for training and test data, (2) the limited availability of theoretical tools to analyze generalization, (3) the lack of reliable confidence estimates. In addition, the majority of work so far has focused on a small set of application domains and threat models.
  </p>
  <p>
    This workshop will bring together experts from the computer security and machine learning communities in an attempt to highlight recent work that contribute to address these challenges. Our agenda will complement contributed papers with invited speakers. The latter will emphasize connections between ML security and other research areas such as accountability or formal verification, as well as stress social aspects of ML misuses. We hope this will help identify fundamental directions for future cross-community collaborations, thus charting a path towards secure and trustworthy ML.
  </p>
  <h2>Sponsor</h2>
  <p>Thank you to the Open Philanthropy Project for sponsoring this event. Their grant will fund a best paper award as well as support for travel.</p>

  <h2>Call For Papers</h2>
  <p>The workshop will include contributed papers. Based on the PC’s recommendation, each paper accepted to the workshop will be allocated either a contributed talk or spotlight presentation, in addition to a poster slot.</p>
  <p>There are two tracks for submissions:</p>
  <ul>
	  <li><b>Research Track:</b> Submissions to this track will introduce novel ideas or results. Submissions should follow the NIPS format and not exceed 4 pages (excluding references, appendices or large figures).</li>
	  <li><b>Encore Track:</b> Papers already accepted at other venues can be submitted to this track. There are no format constraints.</li>
  </ul>
  <p>We invite submissions on <b>any aspect of machine learning that relates to computer security (and vice versa)</b>. This includes, but is not limited to:</p>
  <ul>
	  <li>Training time attacks (e.g., data poisoning)</li>
	  <li>Test time attacks (e.g., adversarial examples, model stealing)</li>
	  <li>Cryptography for machine learning</li>
	  <li>Theoretical foundations of secure machine learning</li>
	  <li>Formal verification of machine learning systems</li>
	  <li>Identifying bugs in machine learning systems</li>
	  <li>Position papers raising new directions for secure machine learning</li>
  </ul>
  <p><b>We particularly welcome submissions that introduce novel datasets and/or organize competitions on novel datasets.</b>
  When relevant, submissions are encouraged to clearly state their <b>threat model</b>, release <b>open-source code</b> and take particular care in conducting <b>ethical research</b>. Reviewing will be performed in a <b>single-blind</b> fashion (reviewers will be anonymous but not authors). Reviewing criteria include (a) <b>relevance</b>, (b) <b>quality</b> of the methodology and experiments, (c) <b>novelty</b>.</p>
  <p>Note that submissions on privacy would be best submitted to the <a href="https://nips.cc/Conferences/2018/Schedule?showEvent=10934" target="_blank">workshop dedicated to this topic</a>.</p>
  <p>This workshop will not have proceedings.</p>
  <p>Contact secml2018-org@googlegroups.com for any questions.</p>


  <h2>Schedule (tentative)</h2>
  <p>The following is a tentative schedule and is subject to change prior to the workshop.</p>

  <table class="table table-sm">
    <tbody>
    <tr>
      <th scope="row">8:45am</th>
      <td>Opening Remarks</td>
      <td>TBD</td>
    </tr>

    <tr><th scope="row" colspan="3">Session 1: Provable methods for secure ML</th></tr>
    <tr>
      <th scope="row">9:00am</th>
      <td>Contributed Talk #1</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">9:15am</th>
      <td>Invited Talk #1</td>
      <td><a href="https://stanford.edu/~aditir/" target="_blank">Aditi Raghunathan</a></td>
    </tr>
    <tr>
      <th scope="row">9:45am</th>
      <td>Contributed Talk #2</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">10:00am</th>
      <td>Poster Spotlights #1</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">10:10am</th>
      <td>Poster Session followed by coffee break</td>
      <td></td>
    </tr>

    <tr><th scope="row" colspan="3">Session 2: ML security and society</th></tr>
    <tr>
      <th scope="row">11:00am</th>
      <td>Keynote</td>
      <td><a href="http://www.danah.org/" target="_blank">danah boyd</a></td>
    </tr>
    <tr>
      <th scope="row">11:45am</th>
      <td>Contributed Talk #3</td>
      <td>TBD</td>
    </tr>

    <tr><th scope="row" colspan="3">Lunch break</th></tr>

    <tr><th scope="row" colspan="3">Session 3: On the connections between ML security, robust optimization, and accountability</th></tr>
    <tr>
      <th scope="row">1:30pm</th>
      <td>Invited Talk #2</td>
      <td><a href="https://beenkim.github.io/" target="_blank">Been Kim</a></td>
    </tr>
    <tr>
      <th scope="row">2:00pm</th>
      <td>Contributed Talk #4</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">2:15pm</th>
      <td>Invited Talk #3</td>
      <td><a href="http://moustaphacisse.com/" target="_blank">Moustapha Cisse</a></td>
    </tr>
    <tr>
      <th scope="row">2:45pm</th>
      <td>Contributed Talk #5</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">3:00pm</th>
      <td>Poster Spotlights #2</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">3:20pm</th>
      <td>Poster Session followed by coffee break</td>
      <td></td>
    </tr>

    <tr><th scope="row" colspan="3">Session 4: ML security from a formal verification perspective</th></tr>
    <tr>
      <th scope="row">4:15pm</th>
      <td>Invited Talk #4</td>
      <td><a href="https://en.wikipedia.org/wiki/Marta_Kwiatkowska" target="_blank">Marta Kwiatkowska</a></td>
    </tr>
    <tr>
      <th scope="row">4:45pm</th>
      <td>Invited Talk #5</td>
      <td><a href="http://pages.cs.wisc.edu/~jha/" target="_blank">Somesh Jha</a></td>
    </tr>
    </tbody>
  </table>

  <h2>Organizing Committee</h2>
  <div class="row justify-content-around">
    <div class="col-lg-1"></div>
    <div class="col-lg-2">
      <img class="rounded-circle" src="nicolas.jpg" height="100px">
      <p>Nicolas Papernot<br /> (Chair)</p>
    </div>
    <div class="col-lg-2">
      <img class="rounded-circle" src="florian.jpg" height="100px">
      <p>Florian Tramer<br /> (Co-chair)</p>
    </div>
    <div class="col-lg-2">
      <img class="rounded-circle" src="kamalika.jpg" height="100px">
      <p>Kamalika Chaudhuri</p>
    </div>
    <div class="col-lg-2">
      <img class="rounded-circle" src="mfredrik.jpg" height="100px">
      <p>Matt Fredrikson</p>
    </div>
    <div class="col-lg-2">
      <img class="rounded-circle" src="photo.png" height="100px">
      <p>Jacob Steinhardt</p>
    </div>
    <div class="col-lg-1"></div>
  </div>

<h2>Program Committee</h2>
<ul>
	<li>Aditi Raghunathan (Stanford University)</li>
	<li>Alexey Kurakin (Google Brain)</li>
	<li>Ananth Raghunathan (Google Brain)</li>
	<li>Anish Athalye (Massachusetts Institute of Technology)</li>
	<li>Arunesh Sinha (University of Michigan)</li>
	<li>Battista Biggio (University of Cagliari)</li>
	<li>Berkay Celik (Pennsylvania State University)</li>
	<li>Catherine Olsson (Google Brain)</li>
	<li>Chang Liu (University of California, Berkeley)</li>
	<li>David Evans (University of Virginia)</li>
	<li>Dimitris Tsipras (Massachusetts Institute of Technology)</li>
	<li>Earlence Fernandes (University of Washington)</li>
	<li>Eric Wong (Carnegie Mellon University)</li>
	<li>Fartash Faghri (University of Toronto)</li>
	<li>Florian Tramer (Stanford University)</li>
	<li>Hadi Abdullah (University of Florida)</li>
	<li>Jamie Hayes (Unversity College London)</li>
	<li>Jonathan Uesato (DeepMind)</li>
	<li>Kassem Fawaz (University of Wisconsin-Madison)</li>
	<li>Kathrin Grosse (CISPA)</li>
	<li>Krishna Gummadi (MPI-SWS)</li>
	<li>Krishnamurthy Dvijotham (Deepmind)</li>
	<li>Matthew Wicker (University of Georgia)</li>
	<li>Nicholas Carlini (Google Brain)</li>
	<li>Nicolas Papernot (Google Brain)</li>
	<li>Octavian Suciu (University of Maryland)</li>
	<li>Pin-Yu Chen (IBM)</li>
	<li>Pushmeet Kohli (DeepMind)</li>
	<li>Rudy Bunel (University of Oxford)</li>
	<li>Shreya Shankar (Stanford University)</li>
	<li>Suman Jana (Columbia University)</li>
	<li>Varun Chandrasekaran (University of Wisconsin-Madison)</li>
	<li>Xiaowei Huang (Liverpool University)</li>
	<li>Yanjun Qi (University of Virginia)</li>
	<li>Yigitcan Kaya (University of Maryland)</li>
	<li>Yizheng Chen (Georgia Tech)</li>
</ul>


</main>



</body></html>
